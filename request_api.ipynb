{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "###############################################################\n",
    "# Author: walterwhites\n",
    "# Hackathon: CrackedDevs Hackathon Jan 2024\n",
    "# This code is subject Devpost Hackathon and restrictions.\n",
    "###############################################################"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-19T23:36:50.743899Z",
     "start_time": "2024-01-19T23:36:50.740710Z"
    }
   },
   "id": "18d853a0bfad585f"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le dataset a été créé avec succès dans le fichier jobs_data.csv.\n"
     ]
    }
   ],
   "source": [
    "api_key = '51bd3e30-5d1d-4033-aed0-3a93edbf2bfb'\n",
    "\n",
    "import requests\n",
    "import csv\n",
    "\n",
    "def get_jobs_from_api(api_key, limit=10, min_salary_usd=None, max_salary_usd=None,\n",
    "                      location_iso=None, job_type=None, degree_required=None, technologies=None):\n",
    "    url = \"https://api.crackeddevs.com/api/get-jobs\"\n",
    "    headers = {\"api-key\": api_key}\n",
    "\n",
    "    all_jobs_data = []\n",
    "    page = 1\n",
    "    \n",
    "    while True:\n",
    "        params = {\n",
    "            \"limit\": limit,\n",
    "            \"page\": page,\n",
    "            \"min_salary_usd\": min_salary_usd,\n",
    "            \"max_salary_usd\": max_salary_usd,\n",
    "            \"location_iso\": location_iso,\n",
    "            \"job_type\": job_type,\n",
    "            \"degree_required\": degree_required,\n",
    "            \"technologies\": technologies\n",
    "        }\n",
    "        response = requests.get(url, headers=headers, params=params)\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            all_jobs_data.extend(data)\n",
    "\n",
    "            if not data:\n",
    "                break  # Exit the loop if no more data is returned (end of pages)\n",
    "\n",
    "            page += 1\n",
    "        else:\n",
    "            print(f\"Erreur lors de la requête à l'API. Code de statut : {response.status_code}\")\n",
    "            return None\n",
    "\n",
    "    return all_jobs_data\n",
    "\n",
    "def create_csv(dataset, csv_filename):\n",
    "    with open(csv_filename, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "        fieldnames = dataset[0].keys() if dataset else []\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "\n",
    "        writer.writeheader()\n",
    "        for row in dataset:\n",
    "            writer.writerow(row)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    jobs_data = get_jobs_from_api(api_key, limit=30)\n",
    "\n",
    "    if jobs_data:\n",
    "        csv_filename = \"jobs_data.csv\"\n",
    "        create_csv(jobs_data, csv_filename)\n",
    "        print(f\"Le dataset a été créé avec succès dans le fichier {csv_filename}.\")\n",
    "    else:\n",
    "        print(\"Impossible de créer le dataset.\")\n",
    "\n",
    "\n",
    "#df = pd.DataFrame(question_data)\n",
    "#df.to_csv('dataset_api.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-19T23:36:54.995608Z",
     "start_time": "2024-01-19T23:36:50.748294Z"
    }
   },
   "id": "initial_id"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
